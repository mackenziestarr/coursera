% Created 2017-08-18 Fri 17:06
% Intended LaTeX compiler: pdflatex
\documentclass[11pt]{article}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{graphicx}
\usepackage{grffile}
\usepackage{longtable}
\usepackage{wrapfig}
\usepackage{rotating}
\usepackage[normalem]{ulem}
\usepackage{amsmath}
\usepackage{textcomp}
\usepackage{amssymb}
\usepackage{capt-of}
\usepackage{hyperref}
\usepackage{amsmath}
\author{Mackenzie Starr}
\date{\today}
\title{}
\hypersetup{
 pdfauthor={Mackenzie Starr},
 pdftitle={},
 pdfkeywords={},
 pdfsubject={},
 pdfcreator={Emacs 24.5.1 (Org mode 9.0.5)},
 pdflang={English}}
\begin{document}

\tableofcontents

\section{Week 1}
\label{sec:org6848b85}
\subsection{Intro}
\label{sec:org70aeddf}
A computer is said to learn from experience E with respect to task T,
and some performance measure P, if its performance on T as measured by
P improves with experience E.

\subsection{Supervised Learning}
\label{sec:org836dc09}
\begin{itemize}
\item Example problem given a dataset of houses where price is on the X
axis and sq. ft is on the Y axis, predict the price for a given
square footage.

\item You input is a data set with the "right" answers. The task is to
produce more of the "right" answers. Since you are trying to predict
a continuous value this is called a regression problem.

\item Knowing the best function to fit to your data is something you gain intuition for?

\item Classification problem: discrete output (0, 1, 2)
\item Regression problem: continuous output (0 - 2)

\item Support vector machines are a thing and they allow a computer to
deal with an infinite number of features.
\end{itemize}

\subsection{Unsupervised Learning}
\label{sec:orgbcc7906}
\begin{itemize}
\item We are given data that has few or no labels and the goal is to find
some structure in the data

\item Google News is an example of this clustering by un-labeled topic,
you don't know what the stories will be about in advanced

\item You don't know in advance any of the labels and you want the machine to label things for you

\item analyzing communications between computers in data center and
optimizing topology for clusters that frequency work together

\item applications of unsupervised learning:
\begin{itemize}
\item clustering
\item separating voices out at a cocktail party ("cocktail party" algorithm) e.g. signal correlation
\end{itemize}
\end{itemize}

\subsection{Model and Cost Function}
\label{sec:org4e0261a}
Notation:
\begin{itemize}
\item input variables are often called features
\item (x,y) is a single training example
\item (x\(^{\text{i}}\), y\(^{\text{i}}\)) the ith training example
\item the function that a learning algorithm produces is often called a hypothesis
\item training set -> learning algorithm -> h()
\begin{itemize}
\item h is a function that maps from x's to y's
\end{itemize}
\item Linear regression with one variable AKA Univarite linear regression

\item[{Hypothesis}] \(h_{\theta}(x) = \theta_{0} + \theta_{1}x\)
\item[{Parameters}] \(\theta_{0},\theta_{01}\)
\item[{Cost function}] \(J(\theta_{0},\theta_{1}) = \frac{1}{2m}\sum\limits_{i=1}^{m}(h_{\theta}(x^{(i)})-y^{(i)})^2\)
\item[{Goal}] minimize \(J(\theta_{0},\theta_{1})\)
\item This cost function is called the "squared error" or "mean squared
error" function and works well for a lot of linear regression
problems
\item You can get better intuition around the goal by simplifying to one
parameter \(\theta_{1}\) graphing \(h_{\theta}(x)\) with some inputs
you'll notice that the corresponding cost function graph for
\(\theta_{1}\) is a parabola converging on \(\theta_{1} = 1\).
\item The best possible line will be such so that the average squared
vertical distances of the scattered points from the line will be the
least. Ideally, the line should pass through all the points of our
training data set. In such a case, the value of J(θ0,θ1) will be 0
\item two parameters can be visualized on a 3D graph or in two dimensions
via a contour plot. We put θ0 on the x axis and θ1 on the y axis,
with the cost function on the vertical z axis.
\end{itemize}

\subsection{Gradient Descent Algorithm}
\label{sec:org49051a4}
\begin{itemize}
\item the gradient descent algorithm can help minimize functions and is
used in many machine learning techniques in our case this is
\(\overset{min}{\theta_{0},\theta_{1}}J(\theta_{0},\theta_{1})\)
\item start with some values for $\backslash$(\(\theta_{\text{0}}\), \(\theta_{\text{1}}\))$\backslash$ (zero is common default value)
\item keep changing \(\theta_{0}, \theta_{1})\ to reduce
  \(J(\theta_{0},\theta_{1})\) until you end up at a minimum
(hopefully)
\item[{repeat until convergence}] \(\theta_{j}:=\theta_{j}-\alpha\frac{\partial}{\partial\theta_{j}}J(\theta_{0},\theta_{1})}\)
\item[{assignment operator}] \(:=\)
\item[{learning rate}] \(\alpha\), controls how big of a step you take on the descent
\item[{derivative term}] \(\alpha\frac{\partial}{\partial\theta_{j}}J(\theta_{0},\theta_{1})\)
\item *\(\theta_{0}\) and \(\theta_{1}\) should be updated simultaneously
as they have inputs dependant on one another
\item at the local optimum your derivative is zero so \(\theta_{1}\) is unchanged
\item with a fixed learning rate \(\alpha\) each successive step is
smaller because the derivative slope value is smaller
\end{itemize}
\subsubsection{intuition}
\label{sec:orgdbcd8ba}
\begin{description}
\item[{simplify to 1 feature}] \(\theta_{1}:=\theta_{1}-\alpha\frac{d}{d\theta_{j}}J(\theta_{1})}\)
\item graph a convex function and pick a point on that line
\item the derivative is the slope of the line that is tagent to the function
\item if the point we picked has a positive slope we get \(\theta_{1}:=\theta_{1}-\alpha(positive number)\) which helps us move closer to the minimum
\item if the point we picked has a negative slope we get \(\theta_{1}:=\theta_{1}-\alpha(negative number)\) which helps us move closer to the minimum
\end{description}
\subsubsection{pitfalls}
\label{sec:org7d0726e}
\begin{itemize}
\item if \(\alpha\) is too small than gradient descent can be slow
\item if \(\alpha\) is too big than you can overshoot the minimum and not converge
\end{itemize}
\subsection{Putting it all together}
\label{sec:orgf2adb8e}
\begin{itemize}
\item we find the best linear fit to the data by finding the slope and
offset values that minimize the cost function
\item the cost function for linear regression is always going to be a
bow-shaped or "convex" function, so there is only one global optimum (no local optimum)
\item "batch" gradient descent means we are using all the training examples in every step of gradient descent (each update sum's examples)
\item there are other versions of gradient descent that window data sets
\item[{linear regression model}] $\backslash$(h\(_{\theta}\)(x)=\(\theta_{\text{0}}\)+\(\theta_{\text{1}}\)x
\item[{cost function}] \(J(\theta_{0},\theta_{1}) = \frac{1}{2m}\sum\limits_{i=1}^{m}(h_{\theta}(x^{(i)})-y^{(i)})^2\)
\item[{gradient descent algorithm}] \(\theta_{j}:=\theta_{j}-\alpha\frac{\partial}{\partial\theta_{j}}J(\theta_{0},\theta_{1})} (for j=1 and j=0)\)
\item we find the best linear fit to the data by finding the slope and
offset values that minimize the cost function
\end{itemize}
\subsubsection{calculating the partial derivative}
\label{sec:org33c7484}
\begin{itemize}
\item expand equation
\begin{itemize}
\item \(\frac{\partial}{\partial\theta_{j}}J(\theta_{0},\theta_{1}) = \frac{\partial}{\partial\theta_{j}}*\frac{1}{2m}\sum\limits_{i=1}^{m}(h_{\theta}(x^{(i)})-y^{(i)})^2\)
\item \(\frac{\partial}{\partial\theta_{j}}*\frac{1}{2m}\sum\limits_{i=1}^{m}(h_{\theta}(x^{(i)})-y^{(i)})^2 = \(\frac{\partial}{\partial\theta_{j}}*\frac{1}{2m}\sum\limits_{i=1}^{m}(\theta_{0}+\theta_{1}x^{(i)}-y^{(i)})^2\)
\end{itemize}
\item figure out partial derivative for \(j=0\) and \(j=1\)
\begin{itemize}
\item \(j = 0 : \frac{\partial}{\partial\theta_{0}}J(\theta_{0},\theta_{1}) = \frac{1}{m}\sum\limits_{i=1}^{m}(h_{\theta}(x^{(i)})-y^{(i)})\) $\backslash$)
\item \(j = 1 : \frac{\partial}{\partial\theta_{1}}J(\theta_{0},\theta_{1}) = \frac{1}{m}\sum\limits_{i=1}^{m}(h_{\theta}(x^{(i)})-y^{(i)})*x^{(i)}\) $\backslash$)
\item @todo calculate these derivations yourself
\end{itemize}
\item plug into gradient descent (repeat until convergence, simultaneously update assignments)
\begin{itemize}
\item \(\theta_{0}:=\theta_{0}-\alpha\frac{1}{m}\sum\limits_{i=1}^{m}(h_{\theta}(x^{(i)})-y^{(i)})\) $\backslash$)
\item \(\theta_{1}:=\theta_{1}-\alpha\frac{1}{m}\sum\limits_{i=1}^{m}(h_{\theta}(x^{(i)})-y^{(i)})*x^{(i)}\) $\backslash$)
\end{itemize}
\end{itemize}
\subsection{Linear Algebra Review}
\label{sec:orgd51db55}
\begin{description}
\item[{matrix}] rectangular array of values, dimension is determined by rows x columns
\item matrices of a specific dimension containing real number are often
notated like this: \mathbb{R}\(^{\text{4x2}}\)
\item to refer to specific elements matrix \(A\) you can use the notation
\(A_{ij}\) to meant the \(i\)th row, \(j\)th column
\item[{vector}] a nx1 matrix, notated as \(\mathbb{R}^{4}\), values
accessed as \(A_{i}\), a 4-dimensional vector has 4
elements
\item in mathematical notation 1-indexed notation is preferred
\item lowercase variables often denote vectors and uppercase variables denote matrices
\end{description}
\subsubsection{Addition and Scalar Multiplication}
\label{sec:org8116229}
\begin{itemize}
\item matrices of the same dimensions add in a straightforward way
\begin{itemize}
\item \(\begin{bmatrix}1 & 2 \\ 3 & 4 \\ 5 & 6 \end{bmatrix} + \begin{bmatrix}1 & 2 \\ 3 & 4 \\ 5 & 6 \end{bmatrix} = \begin{bmatrix}2 & 4 \\ 6 & 8 \\ 10 & 12 \end{bmatrix}\)
\end{itemize}
\item matrices of different dimensions cannot be added
\begin{itemize}
\item \(\begin{bmatrix}1 & 2 \\ 3 & 4 \\ 5 & 6\end{bmatrix} + \begin{bmatrix}1 & 2 \\ 3 & 4\end{bmatrix} = undefined\)
\end{itemize}
\item $\backslash$(3\(\cdot\)\begin{bmatrix}1 \& 2 $\backslash$\ 3 \& 4 \end{bmatrix} produces a matrix of the same dimension where each value is the product of the previous value and 3
\item scalar division works in a similar way
\end{itemize}
\subsubsection{Matrix Vector Multiplication}
\label{sec:org3675250}
\begin{itemize}
\item multiplying a m x n matrix with a vector is done calculating the dot
product of each matrix row with the vector, yeilding a m-dimensional
vector
\end{itemize}
\subsubsection{Matrix Matrix Multiplication}
\label{sec:org475d5f4}
\begin{itemize}
\item for matrix-matrix multiplication you break the second term into
vectors and then combine the columns at the end. a MxN matrix
multipled by a NxO matrix yields a MxO matrix. The N must match in
order to be able to multiply them
\item The ith column of matrix C is obtained by multiplying A with the ith column of B
\item To multiply two matrices, the number of columns of the first matrix must equal the number of rows of the second matrix.
\end{itemize}
\subsubsection{Matrix Multiplication Properties}
\label{sec:orgcae5b2e}
\begin{itemize}
\item regular multiplication is commutative, matrix multiplication is not (A x B is not equal to B x A)
\item regular multiplication is associative and so is matrix multiplication
\item for the identity matrix AB is equal to AB
\end{itemize}
\subsubsection{Matrix inverse and matrix transpose operation}
\label{sec:org50ef47b}
\begin{itemize}
\item if \(A\) is an \(mxm\) (square) matrix and has an inverse: \(AA^{-1}=A^{-1}A=I\)
\item some \(mxm\) matrices don't have an inverse (e.g. all values are zero)
\item singular or degenerate matrices are matrices that don't have an inverse
\end{itemize}

\section{Week 2}
\label{sec:orgff97949}
\subsection{Multivariant Linear Regression}
\label{sec:orgd0a0d0d}
\subsubsection{Notation}
\label{sec:org8607cd0}
\begin{description}
\item[{\(n\)}] number of features
\item[{\(m\)}] number of training examples
\item[{\(x^{(i)}\)}] input of the \(i^{th}\) training example
\item[{\(x_{j}^{(i)}\)}] value of feature \(j\) in \(i^{th}\) training example
\end{description}
\subsubsection{Hypothesis}
\label{sec:org6109f37}
\begin{itemize}
\item previously with univariant linear regression our hypothesis was
\(h_{\theta}(x)=\theta_{0}+\theta_{1}x\)
\item for multivariant we have a polynomial hypothesis \(h_{\theta}(x)=\theta_{0}+\theta_{1}x_{1}+\theta_{2}x_{2}+...+\theta_{n}x_{n}\)
\item if you define \(x_{0}^{(i)} = 1\) than you can normalize the above as
\(h_{\theta}(x)=\theta_{0}x_{0}+\theta_{1}x_{1}+\theta_{2}x_{2}+...+\theta_{n}x_{n}\)
express in matrix multiplication as \(h_{\theta}(x)=\theta^{T}x\)
\item \(\theta^{T}x=\begin{bmatrix}\theta_{0} & \theta_{1} & ... & \theta_{n}\end{bmatrix}\begin{bmatrix}x_{0} \\ x_{1} \\ ... \\ x_{n} \end{bmatrix}=h_{\theta}(x)\)
\end{itemize}
\subsubsection{Gradient descent for multiple variables}
\label{sec:orgbbcedaa}
\begin{itemize}
\item the cost function is again \frac{1}{2m}\(\sum\)\limits\(_{\text{i=1}}^{\text{m}}\)(h\(_{\theta}\)(x\(^{\text{(i)}}\))-y\(^{\text{(i)}}\))\(^{\text{2}}\)$\backslash$) but \(h_{\theta}(x^{(i)})=\theta^{T}(x^{i})\)
\item in the gradient descent formula the \(x\) in the derivative term has
to be altered slightly to account for more than one feature
\(\theta_{j}:=\theta_{j}-\alpha\frac{1}{m}\sum\limits_{i=1}^{m}(h_{\theta}(x^{(i)})-y^{(i)})*x_{j}^{(i)}\)
\item @todo understand this more
\end{itemize}
\subsubsection{Feature scaling \& Mean normalization}
\label{sec:orga238f5f}
\begin{description}
\item[{why?}] if you ensure your features have similar ranges of values than
gradient descent with converge quicker
\item conventionally things are usually scaled \(-1\leq0\leq1\) but having
a similar range \(max-min\) across features is most important, not
the specific high and low value
\item feature scaling is dividing the input values by the range to get a range of 1
\item mean normalization is a technique for getting the average value of 0 for a feature
\item[{combining mean normalization \& feature scaling}] \(x_{i}:=\frac{x_{i}-\mu_{i}}{s_{i}}\)
where \(\mu_{i}\) is average value of x in training set and \(s_{i}\) is the range \(max-min\) (or standard deviation)
\item @todo what is standard deviation
\end{description}
\subsubsection{Learning Rate}
\label{sec:org66109eb}
\begin{itemize}
\item to make sure gradient descent is working correctly you can plot the
the cost function over the number iterations and the cost function
should go down as iterations go up
\item you can also automate the above by defining a threshold in code but
that can be tricky
\item if your cost function value is increasing over the number of
iterations or has a scalloped pattern than you learning rate is
probably too large
\item to choose a proper \(\alpha\) value plot \(J(\theta)\) with different successively larger learning rates \(.001, .003, .01, .03, .1, .3, 1, 3\)
\end{itemize}
\subsubsection{Features \& Polynomial Regression}
\label{sec:orgb36163d}
\begin{description}
\item[{housing prices prediction}] \(h_{\theta}(x)=\theta_{0}+\theta_{1}\cdot frontage + \theta_{2} \cdot depth\)
\item instead of working with the simple features you have, you free to create your own compound features (e.g. \(area\) is a compound feature of \(frontage\cdotdepth\))
\item[{housing prices prediction with compound feature}] \(h_{\theta}(x)=\theta_{0}+\theta_{1}area\)
\item say we wanted had a hypothesis that a cubic function was a good fit
to our data
\(h_{\theta}(x)=\theta_{0}+\theta_{1}x+\theta_{2}x^{2}+\theta_{3}x^{3}\),
the machinery of linear regression still works for this
\(h_{\theta}(x)=\theta_{0}+\theta_{1}x_{1}+\theta_{2}x_{2}+\theta_{3}x_{3}=\theta_{0}+\theta_{1}(size)+\theta_{2}(size)^{2}+\theta_{3}(size)^3\)
\item some algorithms can solve the \texttt{what features do i use?} question by
automatically choosing what features to use and what functions you
want to fit to that data
\end{description}
\subsection{Computing Parameters Analytics}
\label{sec:org42c4ad3}
\subsubsection{Normal Equation}
\label{sec:orge8ebee9}
\begin{itemize}
\item solves for optimal values of the parameters to  \J(\(\theta\)$\backslash$) in one step for some linear regression problems
\item there is no need to do feature scaling with the normal equation
\item \(\theta = (X^{T}X)^{-1}X^{T}y\) where \((X^{T}X)^{-1}\) is the inverse of the matrix \(X^{T}X\) gives you the optimal value for \(\theta\)
\end{itemize}
\begin{center}
\begin{tabular}{ll}
Gradient Descent & Normal Equation\\
\hline
needs to choose \(\alpha\) & no need to choose \(\alpha\)\\
needs many iterations & don't need to iterate\\
scales with large set of features & doesn't scale with large set of features (inverting a very large +10,000 matrix is expensive)\\
 & less versitile (doesn't work with logisitic regression)\\
\end{tabular}
\end{center}
\begin{enumerate}
\item Intuition
\label{sec:org2cc9971}
\begin{itemize}
\item in one-dimension given a scalar value for \(\theta\), and the quadratic function \(J(\theta)=a\theta^{2}+b\theta+c\)
\item to minimize, take the derivative and set to 0, \(\frac{\partial}{\partial\theta}J(\theta)= ... = 0\) and solve for \(\theta\)
\item in the multivariate version if you take the partial derivative of
\(J\) with respect to every parameter if \(\theta_{\text{j}}\) and set that to
\(0\) and solve for \(\theta_{0},...,\theta{n}\) than you can get
all the values to minimize the cost function
\end{itemize}









\item computing this for Singular / Degenerate Matrices
\label{sec:org2aa3245}
\begin{itemize}
\item If \(X^{T}X\) is noninvertible, the common causes might be:
\begin{itemize}
\item Redundant features, where two features are very closely related (i.e. they are linearly dependent)
\item Too many features (e.g. m ≤ n). In this case, delete some features or use "regularization" (to be explained in a later lesson).
\end{itemize}
\end{itemize}
Solutions to the above problems include deleting a feature that is linearly dependent with another or deleting one or more features when there are too many features.
\begin{itemize}
\item @todo what types of matrices are non-invertible?
\end{itemize}
\end{enumerate}
\section{@todo}
\label{sec:org0a89b6c}
\begin{itemize}
\item replicate Solvvy,
\item \url{https://github.etsycorp.com/Engineering/Etsyweb/commit/0c6754d73fbae3b60310b2fdd1e9948f46e675de}

\item come up with basic ML project ideas
\begin{itemize}
\item "cocktail party" algorithm is sweet, separates audio without any
complicated audio processing libraries
\end{itemize}
\item read more about mean squared error function
\end{itemize}
\end{document}
